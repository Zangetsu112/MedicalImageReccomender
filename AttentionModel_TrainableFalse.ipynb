{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9f1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda296d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join('.', \"archive\", \"all-mias\")\n",
    "info = os.path.join('.', \"archive\", \"Info.txt\")\n",
    "mammogram_df = pd.read_csv(info, sep=\" \")\n",
    "mammogram_df.drop(\"Unnamed: 7\", axis=1, inplace=True)\n",
    "\n",
    "tif_dir = 'tiffs'\n",
    "# if not os.path.exists(tif_dir):  \n",
    "os.makedirs(tif_dir, exist_ok=True)\n",
    "from skimage.io import imread, imsave\n",
    "def to_path(c_row):\n",
    "#         image =  imread(os.path.join(base_dir, '%s.pgm' % c_row['REFNUM']))\n",
    "    out_path = os.path.join(tif_dir, '%s.tif' % c_row['REFNUM'])\n",
    "#         imsave(out_path, image)\n",
    "    return out_path\n",
    "mammogram_df['path'] =  mammogram_df.apply(to_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8933f09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 21:00:37.088817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical \n",
    "encoder = LabelEncoder()\n",
    "mammogram_df['CLASS_ID'] = encoder.fit_transform(mammogram_df['CLASS'])\n",
    "mammogram_df['CLASS_VEC'] = mammogram_df['CLASS_ID'].map(lambda x: to_categorical(x, num_classes=len(encoder.classes_)))\n",
    "mammogram_df['SEVERITY'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb492ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>BG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>path</th>\n",
       "      <th>CLASS_ID</th>\n",
       "      <th>CLASS_VEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>tiffs/mdb001.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>tiffs/mdb002.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb003.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb004.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>477.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>tiffs/mdb005.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>500.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>tiffs/mdb005.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mdb006</td>\n",
       "      <td>F</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb006.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mdb007</td>\n",
       "      <td>G</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb007.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mdb008</td>\n",
       "      <td>G</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb008.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mdb009</td>\n",
       "      <td>F</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb009.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mdb010</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>525.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>tiffs/mdb010.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mdb011</td>\n",
       "      <td>F</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb011.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mdb012</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>471.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>tiffs/mdb012.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mdb013</td>\n",
       "      <td>G</td>\n",
       "      <td>MISC</td>\n",
       "      <td>B</td>\n",
       "      <td>667.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>tiffs/mdb013.tif</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mdb014</td>\n",
       "      <td>G</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb014.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mdb015</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>595.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>tiffs/mdb015.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mdb016</td>\n",
       "      <td>G</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb016.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mdb017</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>547.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>tiffs/mdb017.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mdb018</td>\n",
       "      <td>G</td>\n",
       "      <td>NORM</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tiffs/mdb018.tif</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mdb019</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>653.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>tiffs/mdb019.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    REFNUM BG CLASS SEVERITY      X      Y  RADIUS              path  \\\n",
       "0   mdb001  G  CIRC        B  535.0  425.0   197.0  tiffs/mdb001.tif   \n",
       "1   mdb002  G  CIRC        B  522.0  280.0    69.0  tiffs/mdb002.tif   \n",
       "2   mdb003  D  NORM        N    NaN    NaN     NaN  tiffs/mdb003.tif   \n",
       "3   mdb004  D  NORM        N    NaN    NaN     NaN  tiffs/mdb004.tif   \n",
       "4   mdb005  F  CIRC        B  477.0  133.0    30.0  tiffs/mdb005.tif   \n",
       "5   mdb005  F  CIRC        B  500.0  168.0    26.0  tiffs/mdb005.tif   \n",
       "6   mdb006  F  NORM        N    NaN    NaN     NaN  tiffs/mdb006.tif   \n",
       "7   mdb007  G  NORM        N    NaN    NaN     NaN  tiffs/mdb007.tif   \n",
       "8   mdb008  G  NORM        N    NaN    NaN     NaN  tiffs/mdb008.tif   \n",
       "9   mdb009  F  NORM        N    NaN    NaN     NaN  tiffs/mdb009.tif   \n",
       "10  mdb010  F  CIRC        B  525.0  425.0    33.0  tiffs/mdb010.tif   \n",
       "11  mdb011  F  NORM        N    NaN    NaN     NaN  tiffs/mdb011.tif   \n",
       "12  mdb012  F  CIRC        B  471.0  458.0    40.0  tiffs/mdb012.tif   \n",
       "13  mdb013  G  MISC        B  667.0  365.0    31.0  tiffs/mdb013.tif   \n",
       "14  mdb014  G  NORM        N    NaN    NaN     NaN  tiffs/mdb014.tif   \n",
       "15  mdb015  G  CIRC        B  595.0  864.0    68.0  tiffs/mdb015.tif   \n",
       "16  mdb016  G  NORM        N    NaN    NaN     NaN  tiffs/mdb016.tif   \n",
       "17  mdb017  G  CIRC        B  547.0  573.0    48.0  tiffs/mdb017.tif   \n",
       "18  mdb018  G  NORM        N    NaN    NaN     NaN  tiffs/mdb018.tif   \n",
       "19  mdb019  G  CIRC        B  653.0  477.0    49.0  tiffs/mdb019.tif   \n",
       "\n",
       "    CLASS_ID                            CLASS_VEC  \n",
       "0          3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "1          3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "2          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "3          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "4          3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "5          3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "6          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "8          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "9          5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "10         3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "11         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "12         3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "13         4  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "14         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "15         3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "16         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "17         3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "18         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "19         3  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammogram_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa713cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 247 validation 83\n",
      "New Data Size: 1300 Old Size: 247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "raw_train_df, validation_df = train_test_split(mammogram_df, \n",
    "                                   test_size = 0.25, \n",
    "                                   random_state = 335,\n",
    "                                   stratify = mammogram_df[['CLASS_ID', 'SEVERITY']])\n",
    "print('train', raw_train_df.shape[0], 'validation', validation_df.shape[0])\n",
    "\n",
    "train_df = raw_train_df.groupby(['CLASS', 'SEVERITY']).apply(lambda x: x.sample(100, replace = True)\n",
    "                                                      ).reset_index(drop = True)\n",
    "print('New Data Size:', train_df.shape[0], 'Old Size:', raw_train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0883a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "IMG_SIZE = (192, 192)\n",
    "core_datagen = ImageDataGenerator(horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.15, \n",
    "                              width_shift_range = 0.15, \n",
    "                              rotation_range = 5, \n",
    "                              shear_range = 0.01,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range=0.2,\n",
    "                              preprocessing_function = preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850aa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    df_gen = img_data_gen.flow_from_dataframe(in_df, x_col=path_col, y_col=y_col, class_mode = 'raw', **dflow_args)\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb09b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 validated image filenames.\n",
      "Found 83 validated image filenames.\n",
      "Found 83 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(core_datagen, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'CLASS_ID', \n",
    "                            target_size = IMG_SIZE,\n",
    "                            color_mode = 'rgb',\n",
    "                            batch_size = 32)\n",
    "\n",
    "valid_gen = flow_from_dataframe(test_datagen, validation_df, path_col = 'path', y_col = 'CLASS_ID', target_size = IMG_SIZE,\n",
    "                            color_mode = 'rgb',\n",
    "                            batch_size = 83)\n",
    "\n",
    "test_X, test_Y = next(flow_from_dataframe(test_datagen, \n",
    "                            validation_df, \n",
    "                            path_col = 'path',\n",
    "                            y_col = 'CLASS_ID', \n",
    "                            target_size = IMG_SIZE,\n",
    "                            color_mode = 'rgb',\n",
    "                            batch_size = 83))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4c03f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "t_x.shape\n",
    "t_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e6d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 21:00:46.245154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 192, 192, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " vgg16 (Functional)             (None, 6, 6, 512)    14714688    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 6, 6, 512)   2048        ['vgg16[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 6, 6, 64)     32832       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 6, 16)     1040        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 6, 1)      17          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 6, 512)    512         ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 6, 6, 512)    0           ['conv2d_3[0][0]',               \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['multiply[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 512)         0           ['conv2d_3[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " RescaleGAP (Lambda)            (None, 512)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_average_pooling2d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['RescaleGAP[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            903         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,817,704\n",
      "Trainable params: 101,480\n",
      "Non-trainable params: 14,716,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\n",
    "from keras.models import Model\n",
    "in_lay = Input(t_x.shape[1:])\n",
    "base_pretrained_model = VGG16(input_shape =  t_x.shape[1:], include_top = False, weights = 'imagenet')\n",
    "base_pretrained_model.trainable = False\n",
    "pt_depth = 512\n",
    "pt_features = base_pretrained_model(in_lay)\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "# here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "\n",
    "attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(1, \n",
    "                                kernel_size = (1,1), \n",
    "                                padding = 'valid', \n",
    "                                activation = 'sigmoid')(attn_layer)\n",
    "# fan it out to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.5)(gap)\n",
    "dr_steps = Dropout(0.25)(Dense(128, activation = 'elu')(gap_dr))\n",
    "out_layer = Dense(len(encoder.classes_), activation = 'softmax')(dr_steps) # linear is what 16bit did\n",
    "mammo_model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "\n",
    "mammo_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "                           metrics = ['accuracy', 'sparse_categorical_accuracy'])\n",
    "\n",
    "mammo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc087df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('mammo_result2')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5) \n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa51c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/57l9tbzx1sx3gv33wf6_0x_w0000gn/T/ipykernel_97372/3179281902.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  mammo_model.fit_generator(train_gen, steps_per_epoch = 35, validation_data = valid_gen, epochs = 10, callbacks = callbacks_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.7003 - accuracy: 0.3574 - sparse_categorical_accuracy: 0.3574\n",
      "Epoch 1: val_loss improved from inf to 2.92067, saving model to mammo_result2_weights.best.hdf5\n",
      "35/35 [==============================] - 221s 6s/step - loss: 1.7003 - accuracy: 0.3574 - sparse_categorical_accuracy: 0.3574 - val_loss: 2.9207 - val_accuracy: 0.1084 - val_sparse_categorical_accuracy: 0.1084 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.2431 - accuracy: 0.5731 - sparse_categorical_accuracy: 0.5731\n",
      "Epoch 2: val_loss did not improve from 2.92067\n",
      "35/35 [==============================] - 219s 6s/step - loss: 1.2431 - accuracy: 0.5731 - sparse_categorical_accuracy: 0.5731 - val_loss: 3.0354 - val_accuracy: 0.1084 - val_sparse_categorical_accuracy: 0.1084 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.0450 - accuracy: 0.6570 - sparse_categorical_accuracy: 0.6570\n",
      "Epoch 3: val_loss did not improve from 2.92067\n",
      "35/35 [==============================] - 237s 7s/step - loss: 1.0450 - accuracy: 0.6570 - sparse_categorical_accuracy: 0.6570 - val_loss: 3.0290 - val_accuracy: 0.0723 - val_sparse_categorical_accuracy: 0.0723 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8968 - accuracy: 0.7202 - sparse_categorical_accuracy: 0.7202\n",
      "Epoch 4: val_loss improved from 2.92067 to 2.54661, saving model to mammo_result2_weights.best.hdf5\n",
      "35/35 [==============================] - 201s 6s/step - loss: 0.8968 - accuracy: 0.7202 - sparse_categorical_accuracy: 0.7202 - val_loss: 2.5466 - val_accuracy: 0.1084 - val_sparse_categorical_accuracy: 0.1084 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7958 - accuracy: 0.7437 - sparse_categorical_accuracy: 0.7437\n",
      "Epoch 5: val_loss did not improve from 2.54661\n",
      "35/35 [==============================] - 219s 6s/step - loss: 0.7958 - accuracy: 0.7437 - sparse_categorical_accuracy: 0.7437 - val_loss: 2.6783 - val_accuracy: 0.1807 - val_sparse_categorical_accuracy: 0.1807 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7764 - accuracy: 0.7455 - sparse_categorical_accuracy: 0.7455\n",
      "Epoch 6: val_loss did not improve from 2.54661\n",
      "35/35 [==============================] - 756s 22s/step - loss: 0.7764 - accuracy: 0.7455 - sparse_categorical_accuracy: 0.7455 - val_loss: 2.5961 - val_accuracy: 0.1325 - val_sparse_categorical_accuracy: 0.1325 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.7626 - sparse_categorical_accuracy: 0.7626 \n",
      "Epoch 7: val_loss did not improve from 2.54661\n",
      "35/35 [==============================] - 626s 18s/step - loss: 0.7268 - accuracy: 0.7626 - sparse_categorical_accuracy: 0.7626 - val_loss: 2.6713 - val_accuracy: 0.1325 - val_sparse_categorical_accuracy: 0.1325 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.7861 - sparse_categorical_accuracy: 0.7861\n",
      "Epoch 8: val_loss did not improve from 2.54661\n",
      "35/35 [==============================] - 235s 7s/step - loss: 0.6459 - accuracy: 0.7861 - sparse_categorical_accuracy: 0.7861 - val_loss: 2.8243 - val_accuracy: 0.1325 - val_sparse_categorical_accuracy: 0.1325 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7915 - sparse_categorical_accuracy: 0.7915 \n",
      "Epoch 9: val_loss did not improve from 2.54661\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "35/35 [==============================] - 1346s 39s/step - loss: 0.6185 - accuracy: 0.7915 - sparse_categorical_accuracy: 0.7915 - val_loss: 2.7789 - val_accuracy: 0.1205 - val_sparse_categorical_accuracy: 0.1205 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x135325cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammo_model.fit_generator(train_gen, steps_per_epoch = 35, validation_data = valid_gen, epochs = 10, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348c068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommenderAI",
   "language": "python",
   "name": "recommenderai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
